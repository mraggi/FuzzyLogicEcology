\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{color}

\newcommand{\xd}{\mathrm{d}}

%\def\emph{#1}\textbf{#1}
\makeatletter
\numberwithin{equation}{section} %% Comment out for sequentially-numbered
\numberwithin{figure}{section} %% Comment out for sequentially-numbered
\def\proof{\noindent{\bf Proof: }}
\def\qed{ \hskip 20pt{\vrule height7pt width6pt depth0pt}\hfil}

\def\area{{\text{Area}}} %% This is probably the wrong way to do it. Breña: fix it.
\def\cA{{\mathcal{A}}}
\def\cB{{\mathcal{B}}}
\def\cF{{\mathcal{F}}}
\def\cC{{\mathcal{C}}}
\def\cD{{\mathcal{D}}}
\def\cM{{\mathcal{M}}}
\def\cO{{\mathcal{O}}}
\def\cI{{\mathcal{I}}}
\def\cV{{\mathcal{V}}}
\def\cU{{\mathcal{U}}}
\def\cT{{\mathcal{T}}}
\def\cP{{\mathcal{P}}}
\def\cS{{\mathcal{S}}}
\def\cX{{\mathcal{X}}}
\def\cY{{\mathcal{Y}}}

\def\NN{{\mathbb{N}}}
\def\RR{{\mathbb{R}}}
\def\ZZ{{\mathbb{Z}}}
\def\II{{\mathbb{I}}}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{problem}[theorem]{Problem}
% \makeatother

\definecolor{MyBlue}{RGB}{0,0,255}
\definecolor{MyRed}{RGB}{255,0,0}
\def\tcb#1{\textcolor{MyBlue}{#1}}
\def\tcr#1{\textcolor{MyRed}{#1}}

\title{On an application of fuzzy logic to building interaction networks between species given geographical data}

\author[1]{Víctor Anaya}
\author[2]{Víctor Breña}
\author[1]{Daniele Colosi}
\author[1]{Marisol Flores}
\author[1]{Luis Miguel García Velázquez}
\author[1]{Adriana Menchaca Méndez}
\author[2]{Teresa Patiño Cárdenas}
\author[1]{Miguel Raggi}
\author[1]{Sergio Rogelio Tinoco Martínez}
\author[1]{César Torres Miranda}
\affil[1]{Escuela Nacional de Estudios Superiores, Unidad Morelia, UNAM}
\affil[2]{Centro de Ciencias Matemáticas, UNAM}

% Daniele Colosi <dcolosi@enesmorelia.unam.mx>,
% Luis Miguel García Velázquez <luism_garcia@enesmorelia.unam.mx>,
% Marisol Flores <maria.flores@gmail.com>,
% Víctor Anaya <victor_anaya@enesmorelia.unam.mx>,
% Victor Brena <victorb@matmor.unam.mx>,
% Terita <lamoradita@gmail.com>,
% César Torres <catomi@gmail.com>,
% Adriana Menchaca-Mendez <adriana.menchacamendez@gmail.com>,
% Sergio Rogelio Tinoco Martínez <stinoco@enesmorelia.unam.mx>
% Miguel Raggi <mraggi@gmail.com>

\begin{document}
\maketitle

\href{mailto:victor_anaya@enesmorelia.unam.mx}{victor\_anaya@enesmorelia.unam.mx}, \href{mailto:victorb@matmor.unam.mx}{victorb@matmor.unam.mx}, \href{mailto:dcolosi@enesmorelia.unam.mx}{dcolosi@enesmorelia.unam.mx}, \href{mailto:maria.flores@gmail.com}{maria.flores@gmail.com}, \href{mailto:luism\_garcia@enesmorelia.unam.mx}{luism\_garcia@enesmorelia.unam.mx}, \href{mailto:adriana.menchacamendez@gmail.com}{adriana.menchacamendez@gmail.com}, \href{mailto:lamoradita@gmail.com}{lamoradita@gmail.com}. \href{mailto:mraggi@gmail.com}{mraggi@gmail.com}, \href{mailto:stinoco@enesmorelia.unam.mx}{stinoco@enesmorelia.unam.mx}, \href{mailto:catomi@gmail.com}{catomi@gmail.com}

\tcr{No puedo poner los emails!!!!!!! No sé cómo! Alguien arréglelo antes de que rompa la compu!}
\begin{abstract}
	We present a novel way of constructing an interaction network for ecological species using tools from fuzzy logic. We present a few (3???) examples: Quercus Oaxaca (?), Loba-whatever, and redes centro, which were obtained by doing bla and bla \tcr{César?}. We also release computational tools that take as input some observational data and output a network built using the methods described in this paper. Furthermore, the code to analyze said network is also freely released, and a web service is launched, where a user may submit a text file with data and get a network back.
	\vspace{5pt}
Keywords: fuzzy logic, ecology, networks\\
 {\small Mathematics Subject Classification: ???} 
\end{abstract}

\section{Introduction}

In \cite{Hola} and \cite{cesarthesis} the authors do bla bla bla...

In this paper, we improve on that because of bla bla bla, and apply the results to bla bla and bla.

All the source code used for this paper can be freely downloaded and used (under the terms of the license) from
\begin{center}
	\url{https://www.github.com/mraggi/FuzzyLogicEcology}
\end{center}

Traditionally, the way to build an interaction network is to use circles or polygons or whatever, but that has the problems of... \tcr{Marisol + Adriana}

\subsection{A brief introduction to the tools of fuzzy logic}
In this section we introduce the reader to the fuzzy logic tools we used to build the interaction network. For a more complete treatment on the topic, see \cite{FuzzyLogicSuperBook} or \cite{FuzzyLogicSuperBook2}. 

We differentiate between regular sets (\emph{crisp} sets)  and \emph{fuzzy} sets. A fuzzy set is a set in which membership is not a boolean value, but rather is a number between 0 and 1, where a membership of 0 means that the element is not in the set and 1 means the element is definitely in the set. Values in between indicate how much an element belongs to a set.

Formally,
\begin{definition}
	A \textbf{fuzzy set} $A=(X,\mu_A)$ is a set $X$ together with a function $\mu_A:X \to [0,1]$. In this case we call $X$ the \emph{ground set} and $\mu_A$ the \emph{membership function} of $A$. Sometimes we refer to $\mu_A$ as the fuzzy set.
\end{definition}

We wish to define the standard set operations ($\subset,\setminus,\cap,\cup$) on fuzzy sets. 

\begin{definition}
	Let $A$ and $B$ be fuzzy sets on the same ground set $X$. Then,
	\begin{itemize}
		\item $A \subset B$ iff $\mu_A(x) \leq \mu_B(x)$ for every $x\in X$.
		\item $A\setminus B$ is defined by the characteristic function $\mu_{A\setminus B}(x) = \max(0,\mu_A(x)-\mu_B(x))$.
	\end{itemize}
\end{definition}

The above definitions are the only standard definition of $\subset$ and $\setminus$, but the definition of $\cap$ and therefore $\cup$ varies, as there are many ways to do so in a consistent and logical manner. Usually one gives the definition of $\cap$ as $\mu_{A\cap B}(p) := \II(\mu_A(p),\mu_B(p))$, where  $\II : [0,1]^2 \to [0,1]$ is a function that satisfies the same properties as intersection when evaluated in $\{0,1\}$. The definition of $\cup$ follows. \tcr{paperize! Luis Miguel?}. 

\begin{definition}
A \emph{consistent} function $\II : [0,1]^2 \to [0,1]$ is one that for all $a,b,c\in[0,1]$
\begin{enumerate}
  \item $\II(a,b) = \II(b,a)$. (symmetry)
  \item $\II(0,b) = 0$.
  \item $\II(1,b) = b$.
  \item $\II(a,b) \leq \II(c,b)$ if $a \leq c$.
\end{enumerate}
\end{definition}

Once the intersection is defined as $\mu_{A\cap B}(p) := \II(\mu_A(p),\mu_B(p))$, the definition of $\cup$ easily follows as in the inclusion-exclusion principle: $\mu_{A\cup B} = \mu_A + \mu_B - \mu_{A\cup B}$.

It can be easily checked that if one defines intersection this way with a consistent $\II$, it satisfies many of the common properties of sets, such as commutativity for $\cap$ and $\cup$, associativity, De Morgan's laws, etc. when the corresponding crisp set properties are satisfied as well \tcr{paperize! Luis Miguel?}.


%% new section? I don't know.

In this work we will consider two different definitions of $\II$. Both have advantages and disadvantages, which we discuss later.

The first definition we shall consider involves defining the operations akin to when considering independent sets in probability: $\II(a,b) = ab$, so that $A\cap B$ is defined by the membership function $\mu_{A\cap B} (x) := \mu_A(x)\mu_B(x)$, and therefore $A\cup B$ is defined by the membership function $\mu_{A\cup B} (x) := \mu_A(x)+\mu_B(x)-\mu_A(x)\mu_B(x)$.

The second definition, also quite common, is to define $\II(a,b) = \min(a,b)$. In this scenario, we observe that $\mu_{A\cup B}(p) = \max(\mu_A(p),\mu_B(p))$.

\section{Building the network}

The main idea behind the method is that instead of considering the distribution area of a species as a crisp set, we consider the distribution as a fuzzy set. The motivation behind this is that given an observation of an individual of a certain species, the area of effect of this individual in its interaction with other species will decay the further away one moves from this observation. \tcr{This sentence is terrible. Rewrite. \tcr{Luis Miguel}}

Let $\Omega \subset \RR^2$ denote the full area of distribution we are considering. Let $P$ denote a point in $\Omega$ and $C > 0$ be real constant number. We define $f_P:\Omega \to [0,1]$ in the following way:
	$$f_P(Q) = e^{-C\left[d(P,Q)^2\right]}.$$
	where $d(P,Q)$ denotes the (Euclidean) distance from $P$ to $Q$.

	Now, for a certain species $\cA$, let $A \subset \Omega$ denote the set of observed locations of an individual of that species. It is common to find such data when doing field work of this type and ... \tcr{César? O quizás en la intro y aquí nada más decir ``As we previously mentioned, ...''}.

  \begin{definition}
	We define the \textbf{area of distribution} of species $\cA$ as the fuzzy set given by the following membership function:
		$$\mu_A = \cup_{a\in A} f_a$$
  \end{definition}
  
	\begin{figure}
	\begin{center}
		\includegraphics[scale=0.35]{./distribucion.png}
		\caption{Visualization of the area of distribution of a species}
	\end{center}
	
	\end{figure}
	
	Following the standard way of constructing interaction networks based on geographical data (\cite{cesarthesis}, \cite{cesarpaper1}), we build a weighted directed graph $D=(V,E)$ where $V$ is the set of species, and there is an edge $\cA \to \cB$ if their respective areas of distribution of $\cA$ and $\cB$ intersect, and the weight of this edge is defined as
	$$w(\cA \to \cB) = \frac{\area(\cA\cap\cB)}{\area(\cB)}$$

	Translating the above definition to the fuzzy world, we may calculate the weight as follows: if $\mu_A$ and $\mu_B$ are the respective membership functions of $\cA$ and $\cB$ as defined above, when $\II$ is the product function,
	$$w_P(\cA \to \cB) := \left(\int_\Omega \mu_A\mu_B\right)\big/\left(\int_\Omega \mu_A\right) $$
	and when $\II$ is the $\min$ function,
	$$w_M(\cA \to \cB) := \left(\int_\Omega \min(\mu_A,\mu_B)\right)\big/\left(\int_\Omega \mu_A\right) $$
	
\subsection{Calculating weights numerically}

We are left with the following computational problem: Given a set of species and for each species a set of points representing the observational data of the species in question, calculate the weighted digraph as above.

Obviously an analytical approach is a terrible way to do it \tcr{Bah, justifiquen esto uds. Daniele? Alguien?}

So we rely on numerical methods instead. First we'll describe how to find $\mu_A$ for each species $\cA$, and then we proceed to find $w(\cA\to\cB)$ for each pair of species $\cA$,$\cB$.

Divide $\Omega$ into an $n\times n$ grid. Then, each $\mu_A$ can be discretized and represented by an $n\times n$ matrix of real numbers, where every point in the $n\times n$ grid contains a number in $[0,1]$. The higher $n$ is, the better the approximation. For all our experimental results, we found that $n \approx 5000$ is more than enough to get an accurate approximation, in the sense that there is no noticeable difference between the edge weights when $n = 5000$ and when $n = 20,000$. \tcr{Alguien se quisiera aventar un análisis de error? No? That's what I thought.}


\subsection{Normalizing}

	Before going into detail of how to normalize the data in order to calculate the integrals numerically, we discuss allowing some tiny error into our calculations in order to reduce $\Omega$ to a bounded set. This discussion will have the added benefit of making the computation much faster. \tcr{paperize. And probably re-write. Daniele!! I tried, but couldn't quite get it.} 
	
	In a brute force approach, since for every point in the grid we have to consider every observation of said species, calculating the matrix associated with $\mu_A$ takes at least $\Theta(|A|n^2)$ time. To speed up computations by sacrificing \tcr{(a tiny amount of)} accuracy, note that 
		$$\mu_A \leq \sum_{a\in A} f_a.$$
		
		\tcr{Uh... paperize the ``a tiny amount of'' part. Daniele}
		
	We note that the exponential decay in the formula for $f_a$ gives a quick way to only affect the area near point $a$. Therefore, if we admit an error of $\varepsilon > 0$ for each point in the grid, we only need to compute $f_a(p)$ for points $p$ near $a$ inside a circle of radius $R$, where
		$$R := f_a^{-1}(\varepsilon/|A|) = \sqrt{-\log\left(\frac{\varepsilon}{|A|C}\right)}$$
	
	In this way, calculating the matrix associated with $\mu_A$ takes $\Theta(|A|R^2 + n^2)$, a considerable speedup. This assumes, of course, that each point in the grid can be calculated in $\Theta(|A|)$ time, but this is not immediately obvious how to do so when $\II$ is the product. In the next section we make it so. \tcr{paperize. Marisol o Adriana o Sergio}.
	
	With this in mind, we proceed to normalize as follows:
	
	\begin{center}
		\includegraphics[scale=0.5]{./continuoamalla.pdf}
	\end{center}
	
	The second function just involves multiplying each coordinate by $n$ so it is easy. \tcr{paperize. Daniele} 
	
	Consider the bounding box in $\Omega$ of the points in the data set. That is, let $O=(mx,my)$ and $W=(Mx,My)$, where $mx,my,Mx,My$ denote the minimum and maximum $x$ and $y$ values in the dataset respectively (of all observations for all species in question) respectively.
	
	Let $F=W-O$. Then, $b_x = R/|F_x|$ and $b_y = R/|F_y|$ are the $x$ and $y$ borders respectively in $[0,1]\times[0,1]$. For any point falling outside the border, the value of $\mu$ would, by the definition of $R$, be a number that is less than $\varepsilon$ and therefore can be ignored. Every point in the dataset gets normalized in this way.
	
	Also, $C$ has to be transformed into $C_x := C\frac{F_x^2}{n^2}$ and $C_y :=  C\frac{F_y^2}{n^2}$, because of \tcr{Daniele said so. I agreed he was correct, but I don't remember.}

\subsection{Finding \texorpdfstring{$\mu_A$}{mu\_A}}
Computing the matrix representing $\mu_A$ is straightforward when considering $\II$ as the min function: For each point in the grid we must simply find the closest point $a\in A$ and calculate $f_a$.

When $\II$ is the product function, however, things get a little more tricky \tcr{paperize}. By the inclusion-exclusion principle we have
	$$\mu_A = \sum_{a\in A} f_{a} - \sum_{a,b \in \binom{A}{2}} f_a f_b + \sum_{a,b,c \in \binom{A}{3} } f_a f_{b} f_{c} + \dots + (-1)^{|A|+1} \prod_{a\in A} f_a.$$

	We factor $\mu_A$ as follows:
$$\mu_A = 1-\prod_{a\in A} (1-f_a)$$

	

	\subsection{Finding \texorpdfstring{$w$}{w}}
	
	Once we have $\mu$ for every species, it's time to calculate $\int \mu_A\mu_B$ for every pair of species $\cA$, $\cB$. The straightforward approach has a complexity of $O(s^2n^2)$, where $s$ is the number of species and $n$ is the size of the grid.
	
	We may speed up this computation when $\II$ is the product with the following trick. 
	
	Note that 
		$$n^2\int \mu_A \mu_B \approx \sum_{0\leq x < n} \sum_{0\leq y < n} \mu_A[x,y]\mu_B[x,y]$$
	
	Let $\nu_A$ and $\nu_B$ denote vectors that result from flattening $\mu_A$ and $\mu_B$. Then the r.h.s. of the previous equation is simply the dot product $\nu_A\cdot \nu_B$.
	
	So consider the $s\times n^2$ matrix 
	$$M = \begin{bmatrix}
	        \longleftarrow & \nu_0 & \longrightarrow \\
	        \longleftarrow & \nu_1 & \longrightarrow \\
	          & \dots &   \\
					\longleftarrow & \nu_{s-1} & \longrightarrow \\
	      \end{bmatrix}.
	$$
Then, $MM^T$ is an $s\times s$ matrix whose $(i,j)$-th entry contains $\nu_A\cdot \nu_B \approx n^2\int \mu_A \mu_B$. However, $MM^T$ can be computed efficiently with fast matrix multiplication algorithms (\cite{strassen}) \tcr{(Marisol, tú te los sabes seguramente, pon unas palabritas de ellos y di que son super chidos y que no se que)}. Unfortunately, when $\II = \min$ this speedup is not possible, as fast matrix multiplication relies on the fact that $+$ and $\times$ are distributive.

Note also that the algorithms described here are highly parallelizable, since calculating the matrix associated with $\mu_A$ for one species does not rely on observations from any other species, and the fast matrix multiplication algorithms are highly paralellizable \tcr{paperize. Marisol: do this}. Indeed, the provided software benefits considerably by using a computer with many cores. \tcr{paperize?}

\subsection{Advantages and disadvantages of min over product}

We gave two parallel ways to construct the distribution network: using products and using min. In this section we discuss the advantages and disadvantages of using each.

The clearest disadvantage of using the product is that $A\cap A \neq A$. So the weighted edge $w_P(\cA \to \cA) \neq 1$. This sucks. In general, in our experimental data, the edge weights become quite small. A way to alleviate this is to consider
	$$\widehat{w_P}(\cA \to \cB) := \left(\int_\Omega \mu_A\mu_B\right)\big/\left(\int_\Omega \mu_A^2\right)$$
	
This gives much better edge weights \tcr{paperize... justify? Luis Miguel?}, but has the disadvantage that an edge weight may be greater than 1. Using our experimental data. Since the edge weight $w(\cA \to \cB)$ is supposed to represent how what percentage of the area of distribution of $\cA$ is contained in the area of distribution of $\cB$, a value greater than 1 would mean that $\cA$ is more strongly contained in $\cB$ than in itself. This makes sense!! It's not bad!

\section{Experiments and results}

\subsection{Digraphs}
The following digraphs were obtained as a result of the algorithms described in the previous section. \tcr{(mm... damos las gráficas? La más chica es una matriz de $56\times56$, aunque podríamos dar sólo las aristas más pesadas... no sé)}

\subsection{Analysis of the digraphs}
\tcr{Is this section for second paper? Or what?}

This graphs are cool because here is the robustness and the analysis revealed deep and important truths \tcr{(Yo les doy los resultados del análisis. Uds. escriben por qué, para qué, cómo, cuándo, etc.)}. 

\section{Conclusions}

Finally, we conclude this awesome work. Please accept this paper!! \tcr{Later}


\section*{Acknowledgements}

This project was supported by PAPIIT IA106316.


\bibliographystyle{myamsalpha}
\bibliography{references}


\appendix
\section{On the mathematical expression of the area distribution}

\tcr{Me gustaría decir aquí que usamos estas expresiones como unit tests del programa. Adriana? Marisol? Sergio?}

In this appendix we provide an analytic expression of the integral of the (product of the) membership functions in an ideal case, namely where the integral is extended over ${\mathbb R}^2$. Although this is unrealistic because the species are distributed on the surface of the Earth, we consider such an idealisation justified by the exponential decay of the functions $f_P$ defined above.

\tcr{Suggestion: so far, we have been using $f_a$ where $a$ is a point, not $f_i$ where $i\in\ZZ$.}

Given a species $A$, we denote by $N_A$ the number of its individuals; then the expression (\ref{mu}) reads:
\begin{equation}
\mu_A = \sum_{i=1}^{N_A} f_{i} - \sum_{i \neq j} f_{i} f_{j} + \sum_{i \neq j \neq k,  i \neq k } f_{i} f_{j} f_{k} + \cdots + (-1)^{N_A-1} \prod_{i=1}^{N_A} f_i,
\end{equation}
or, in more compact notation,
\begin{equation}
\mu_A = \sum_{n=1}^{N_A} (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^{N_A} f_{i_1} \cdots f_{i_n}.
\end{equation}
Now we compute the integral of $\mu_A$ over all of space, i.e. over ${\mathbb R}^2$:
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A(x,y)
% \nonumber\\
%&=  \sum_{i=1}^{N_A} \int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) - \sum_{i \neq j} \int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) f_{j}(x,y)  \nonumber\\
%& + \sum_{i \neq j \neq k,  i \neq k } \int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) f_{j}(x,y) f_{k}(x,y) + \cdots + (-1)^{N_A-1} \int_{{\mathbb R}^2} \xd x \, \xd y \,\prod_{i=1}^{N_A} f_i(x,y), \nonumber\\
%&
= \sum_{n=1}^{N_A} (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^{N_A} \int_{{\mathbb R}^2} \xd x \, \xd y \,  f_{i_1} (x,y)\cdots f_{i_n} (x,y).
\end{align}
Notice that the $f_i$ are Gaussian distributions, then the first integral in the r.h.s. of the second line of the above expression results to be
\begin{equation}
\int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) = \frac{\pi}{C}.
\end{equation}
We consider the integral of the product of $n$ Gaussian distributions:
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \,  f_{i_1} (x,y)\cdots f_{i_n} (x,y) = \int_{{\mathbb R}^2} \xd x \, \xd y \,  \exp \left[ -C \sum_{\alpha=1}^n \left( (x-x_{i_{\alpha}})^2 + (y-y_{i_{\alpha}})^2 \right) \right].
\end{align}
Notice that 
\begin{equation}
\sum_{\alpha=1}^n  \left( (x-x_{i_{\alpha}})^2 +(y-y_{i_{\alpha}})^2 \right) = n (x^2+y^2) -2x  \sum_{\alpha=1}^n x_{i_{\alpha}} + \sum_{\alpha=1}^n x_{i_{\alpha}}^2 -2y \sum_{\alpha=1}^n y_{i_{\alpha}} + \sum_{\alpha=1}^n y_{i_{\alpha}}^2.
% \underbrace{\sum_{\alpha=1}^n x_{i_{\alpha}} }_{X_{1,n}}+ \underbrace{\sum_{\alpha=1}^n x_{i_{\alpha}}^2}_{X_{2,n}} -2y \underbrace{\sum_{\alpha=1}^n y_{i_{\alpha}} }_{Y_{1,n}}+ \underbrace{\sum_{\alpha=1}^n y_{i_{\alpha}}^2}_{Y_{2,n}}.
\end{equation}
So, 
\begin{align}
&\int_{{\mathbb R}^2} \xd x \, \xd y \,  f_{i_1} (x,y)\cdots f_{i_n} (x,y) \nonumber\\
&= \int_{{\mathbb R}^2} \xd x  \ \xd y \, \exp \left[ -Cn(x^2+y^2) +2C \sum_{\alpha=1}^n \left( x_{i_{\alpha}} x +y_{i_{\alpha}} y \right) - C \sum_{\alpha=1}^n \left(x_{i_{\alpha}}^2 + y_{i_{\alpha}}^2 \right) \right], \nonumber\\
%&= \frac{\pi}{nC} \exp \left[ \frac{C(X_{1,n}^2+Y_{1,n}^2)}{n}  - C(X_{2,n}+Y_{2,n})\right], \nonumber\\
&= \frac{\pi}{nC} \exp \left[ \frac{C(\left( \sum_{\alpha=1}^n x_{i_{\alpha}}\right)^2+\left( \sum_{\alpha=1}^n y_{i_{\alpha}}\right)^2)}{n}  - C \sum_{\alpha=1}^n (x_{i_{\alpha}}^2+y_{i_{\alpha}}^2)\right], \nonumber\\
&=  \frac{\pi}{nC} \exp \left[ - \frac{C}{n} \sum_{1=\alpha<\beta}^n \left((x_{i_\alpha}-x_{i_\beta})^2 + (y_{i_{\alpha}}-y_{i_{\beta}})^2 \right) \right], \nonumber\\
&=  \frac{\pi}{nC} \exp \left[ - \frac{C}{n} \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 \right],
\end{align}
where $d_{i_{\alpha} i_{\beta}}$ is the (euclidean) distance between point $P_{i_{\alpha}} =(x_{i_{\alpha}} ,y_{i_{\alpha}} )$ and point $P_{i_{\beta}}=(x_{i_{\beta}},y_{i_{\beta}})$. Finally
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A&= \sum_{n=1}^{N_A} (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^{N_A} \frac{\pi}{nC} \exp \left[ - \frac{C}{n} \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 \right], \\
&= \frac{\pi}{C} \left[ N_A - \frac12  \sum_{ 1=i_1< i_2}^{N_A} \exp \left[- \frac{C}{2}  d_{i_{1} i_{2}}^2 \right] + \frac{1}{3}  \sum_{ 1=i_1< i_2 <i_3 }^{N_A}  \exp \left[ - \frac{C}{3} \sum_{1=\alpha < \beta}^3 d_{i_{\alpha} i_{\beta}}^2 \right] + \cdots
\right].
\end{align}
Analogously we obtain the integral of the product of two membership functions of two species $A$ and $B$,
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B &=  \sum_{n=1}^{N_A} \sum_{\tilde{n}=1}^{N_B} (-1)^{n+\tilde{n}} \sum_{ 1=i_1< \cdots <i_n }^{N_A} \sum_{ 1=\tilde{i}_1< \cdots <\tilde{i}_{\tilde{n}} }^{N_B} \frac{\pi}{(n+\tilde{n})C}
 \nonumber\\
& \exp \left[ - \frac{C}{n+\tilde{n}} \left( \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 + \sum_{1=\alpha < \beta}^{\tilde{n}} d_{\tilde{i}_{\alpha} \tilde{i}_{\beta}}^2 +
% \right. \right. \nonumber\\
%& \left. \left. 
\sum_{\alpha=1}^n \sum_{\tilde{\alpha}=1}^{\tilde{n}} 
d_{i_{\alpha} \tilde{i}_{\tilde{\alpha}}}^2
%\left[ (x_{i_{\alpha}} - x_{\tilde{i}_{\tilde{\alpha}}})^2 + (y_{i_{\alpha}} - y_{\tilde{i}_{\tilde{\alpha}}})^2\right]
\right) \right].
\end{align}

\section{Toy models}
\subsection{\texorpdfstring{$N_A=1$}{NA=1}, \texorpdfstring{$N_B=1$}{NB=1}}
We have in this case (here and in the following we indicate the indices - including the numbers - relative to the species $B$ with a tilde),
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A = \int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_B =  \frac{\pi}{C}
\end{align}
and
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B =  \frac{\pi}{2C} e^{- \frac{C}{2}d^2_{1\tilde{1}}}.
\end{align}
being $d_{1\tilde{1}}$ the distance between the individuals of the species $A$ and $B$.

\subsection{\texorpdfstring{$N_A=2$}{NA=1}, \texorpdfstring{$N_B=1$}{NB=1}}
We denote with $a_1$ and $a_2$ the two individual of the species $A$ and with $b$ the one of species $B$.  Then, we have in this case
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A&= \sum_{n=1}^{2} (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^{2} \frac{\pi}{nC} \exp \left[ - \frac{C}{n} \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 \right], \\
&= \frac{\pi}{C} \left[ 2 - \frac12  \sum_{ 1=i_1< i_2}^{2} \exp \left[- \frac{C}{2}  d_{i_{1} i_{2}}^2 \right]  \right], \\
&= \frac{\pi}{C} \left[ 2 - \frac12  e^{- \frac{C}{2}  d_{{1} {2}}^2 } \right],
\end{align}
being $d_{12}$ the distance between $a_1$ and $a_2$, and
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A^2 &=  \sum_{n=1}^{2} \sum_{\tilde{n}=1}^{2} (-1)^{n+\tilde{n}} \sum_{ 1=i_1< \cdots <i_n }^{2} \sum_{ 1=\tilde{i}_1< \cdots <\tilde{i}_{\tilde{n}} }^{2} \frac{\pi}{(n+\tilde{n})C}
 \nonumber\\
& \exp \left[ - \frac{C}{n+\tilde{n}} \left( \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 + \sum_{1=\alpha < \beta}^{\tilde{n}} d_{\tilde{i}_{\alpha} \tilde{i}_{\beta}}^2 +
\sum_{\alpha=1}^n \sum_{\tilde{\alpha}=1}^{\tilde{n}}  d_{i_{\alpha} \tilde{i}_{\tilde{\alpha}}}^2 \right) \right], \\
&= \frac{\pi}{C} \left[ 1+e^{- \frac{C}{2}d^2_{12}} - \frac{4}{3} e^{- \frac{2C}{3} d^2_{1 2} } + \frac{1}{4} e^{- C d_{12}^2 }  \right].
\end{align}
Also
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B &=  \sum_{n=1}^{2} \sum_{\tilde{n}=1}^{1} (-1)^{n+\tilde{n}} \sum_{ 1=i_1< \cdots <i_n }^{2} \sum_{ 1=\tilde{i}_1< \cdots <\tilde{i}_{\tilde{n}} }^{1} \frac{\pi}{(n+\tilde{n})C}
 \nonumber\\
& \exp \left[ - \frac{C}{n+\tilde{n}} \left( \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 + \sum_{1=\alpha < \beta}^{\tilde{n}} d_{\tilde{i}_{\alpha} \tilde{i}_{\beta}}^2 +
\sum_{\alpha=1}^n \sum_{\tilde{\alpha}=1}^{\tilde{n}}  d_{i_{\alpha} \tilde{i}_{\tilde{\alpha}}}^2 \right) \right], \\
&=  \sum_{n=1}^{2}  (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^{2}  \frac{\pi}{(n+1)C}
 \exp \left[ - \frac{C}{n+1} \left( \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 +
\sum_{\alpha=1}^n  d_{i_{\alpha} {\tilde{1}}}^2 \right) \right], \\
&= \frac{\pi}{C} \left[  \frac12 \sum_{ 1=i_1 }^{2} \exp \left( - \frac{C}{2} d_{i_1 \tilde{1}}^2 \right)  - \frac{1}{3} \exp \left( -\frac{C}{3} [d_{12}^2 + d_{1 \tilde{1}}^2 + d_{2 \tilde{1}}^2 ]\right)  \right], \\
&= \frac{\pi}{C} \left[  \frac12  \exp \left( - \frac{C}{2} d_{1 \tilde{1}}^2 \right) + \frac12  \exp \left( - \frac{C}{2} d_{2 \tilde{1}}^2 \right)  - \frac{1}{3} \exp \left( -\frac{C}{3} [d_{12}^2 + d_{1 \tilde{1}}^2 + d_{2 \tilde{1}}^2 ]\right)  \right],  
\end{align}
where $d_{i_{\alpha} \tilde{1}}$ is the distance between $a_{\alpha}$ and $b$.

\begin{itemize}
	\item
Suppose that $d_{1 \tilde{1}} \ll 1$, namely that $b$ is extremely close to $a_1$ (and consequently $d_{12} \simeq d_{2 \tilde{1}}$). In that case,
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B 
= \frac{\pi}{C} \left[  \frac12  + \frac12  \exp \left( - \frac{C}{2} d_{12 }^2 \right)  - \frac{1}{3} \exp \left( -\frac{2C}{3} d_{12}^2 \right)  \right].
\end{align}
The weight $w_{AB}$ of the link $A \rightarrow B$ then results
\begin{align}
w_{AB} = \frac{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B}{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A^2} = \frac{ \frac12  + \frac12  e^{ - \frac{C}{2} d_{12 }^2 }  - \frac{1}{3} e^{-\frac{2C}{3} d_{12}^2 } }{ 1+e^{- \frac{C}{2}d^2_{12}} - \frac{4}{3} e^{- \frac{2C}{3} d^2_{1 2} } + \frac{1}{4} e^{- C d_{12}^2 } },% = \frac12 \frac{I}{I+G},
\end{align}
%where $I= 1+e^{- \frac{C}{2}d^2_{12}} - \frac{2}{3} e^{- \frac{2C}{3} d^2_{1 2} }$ and $G= - \frac{2}{3} e^{- \frac{2C}{3} d^2_{1 2} } + \frac{1}{4} e^{- C d_{12}^2 } $
and we see that the maximum value for $w_{AB}$ is $\frac{2/3}{2/3+1/4} = \frac{8}{11}$ and the minimum value is $\frac12$. The weight $w_{BA}$ of the link $B \rightarrow A$ then results
\begin{align}
w_{BA} = \frac{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B}{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_B^2} = \frac{ \frac12  + \frac12  e^{ - \frac{C}{2} d_{12 }^2 }  - \frac{1}{3} e^{-\frac{2C}{3} d_{12}^2 } }{ \frac12 } = 1+e^{- \frac{C}{2}d^2_{12}} - \frac{2}{3} e^{- \frac{2C}{3} d^2_{1 2} },% = \frac12 \frac{I}{I+G},
\end{align}
with maximum value equal to 1 and minimum value equal to $\frac{4}{3}$.
	
	\item In the case that $b$ is equidistant from $a_1$ and $a_2$, i.e. $d_{1 \tilde{1}} = d_{2 \tilde{1}}$, we have
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B 
= \frac{\pi}{C} \left[    \exp \left( - \frac{C}{2} d_{1\tilde{1} }^2 \right)  - \frac{1}{3} \exp \left( -\frac{C}{3} [d_{12}^2 + 2 d_{1 \tilde{1}}^2] \right)  \right].
\end{align}
The weights result to be given by
\begin{align}
w_{AB} = \frac{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B}{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A^2} = \frac{  e^{- \frac{C}{2} d_{1\tilde{1} }^2 }  - \frac{1}{3} e^{-\frac{C}{3} [d_{12}^2 + 2 d_{1 \tilde{1}}^2] }  }
{ 1+e^{- \frac{C}{2}d^2_{12}} - \frac{4}{3} e^{- \frac{2C}{3} d^2_{1 2} } + \frac{1}{4} e^{- C d_{12}^2 } },% = \frac12 \frac{I}{I+G},
\end{align}
with minimum and maximum values respectively equal to 0 and $\frac{2/3}{11/12}=\frac{8}{11}$; and
\begin{align}
w_{BA} = \frac{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B}{\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_B^2} = \frac12 e^{- \frac{C}{2} d_{1\tilde{1} }^2 }  - \frac{1}{6} e^{-\frac{C}{3} [d_{12}^2 + 2 d_{1 \tilde{1}}^2] },
\end{align}
with minimum and maximum values respectively equal to 0 and $\frac{1}{3}$.
	
\end{itemize}



\end{document}