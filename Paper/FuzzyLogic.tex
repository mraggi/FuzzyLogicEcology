\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{authblk}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{color}

\newcommand{\xd}{\mathrm{d}}

%\def\emph{#1}\textbf{#1}
\makeatletter
\numberwithin{equation}{section} %% Comment out for sequentially-numbered
\numberwithin{figure}{section} %% Comment out for sequentially-numbered
\def\proof{\noindent{\bf Proof: }}
\def\qed{ \hskip 20pt{\vrule height7pt width6pt depth0pt}\hfil}

\def\area{{\text{Area}}} %% This is probably the wrong way to do it. Breña: fix it.
\def\cA{{\mathcal{A}}}
\def\cB{{\mathcal{B}}}
\def\cF{{\mathcal{F}}}
\def\cC{{\mathcal{C}}}
\def\cD{{\mathcal{D}}}
\def\cM{{\mathcal{M}}}
\def\cO{{\mathcal{O}}}
\def\cI{{\mathcal{I}}}
\def\cV{{\mathcal{V}}}
\def\cU{{\mathcal{U}}}
\def\cT{{\mathcal{T}}}
\def\cP{{\mathcal{P}}}
\def\cS{{\mathcal{S}}}
\def\cX{{\mathcal{X}}}
\def\cY{{\mathcal{Y}}}

\def\NN{{\mathbb{N}}}
\def\RR{{\mathbb{R}}}
\def\ZZ{{\mathbb{Z}}}
\def\II{{\mathbb{I}}}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{problem}[theorem]{Problem}
% \makeatother

\definecolor{MyBlue}{RGB}{0,0,255}
\definecolor{MyRed}{RGB}{255,0,0}
\def\tcb#1{\textcolor{MyBlue}{#1}}
\def\tcr#1{\textcolor{MyRed}{#1}}

\title{On an application of fuzzy logic to building interaction networks between species given geographical data}

\author[1]{Víctor Anaya}
\author[2]{Víctor Breña}
\author[1]{Daniele Colosi}
\author[1]{Marisol Flores}
\author[1]{Luis Miguel García Velázquez}
\author[1]{Adriana Menchaca Méndez}
\author[2]{Teresa Patiño Cárdenas}
\author[1]{Miguel Raggi}
\author[1]{Sergio Rogelio Tinoco Martínez}
\author[1]{César Torres Miranda}
\affil[1]{Escuela Nacional de Estudios Superiores, Unidad Morelia, UNAM}
\affil[2]{Centro de Ciencias Matemáticas, UNAM}

% Daniele Colosi <dcolosi@enesmorelia.unam.mx>,
% Luis Miguel García Velázquez <luism_garcia@enesmorelia.unam.mx>,
% Marisol Flores <maria.flores@gmail.com>,
% Víctor Anaya <victor_anaya@enesmorelia.unam.mx>,
% Victor Brena <victorb@matmor.unam.mx>,
% Terita <lamoradita@gmail.com>,
% César Torres <catomi@gmail.com>,
% Adriana Menchaca-Mendez <adriana.menchacamendez@gmail.com>,
% Sergio Rogelio Tinoco Martínez <stinoco@enesmorelia.unam.mx>
% Miguel Raggi <mraggi@gmail.com>

\begin{document}
\maketitle

\href{mailto:victor_anaya@enesmorelia.unam.mx}{victor\_anaya@enesmorelia.unam.mx}, \href{mailto:victorb@matmor.unam.mx}{victorb@matmor.unam.mx}, \href{mailto:dcolosi@enesmorelia.unam.mx}{dcolosi@enesmorelia.unam.mx}, \href{mailto:maria.flores@gmail.com}{maria.flores@gmail.com}, \href{mailto:luism\_garcia@enesmorelia.unam.mx}{luism\_garcia@enesmorelia.unam.mx}, \href{mailto:adriana.menchacamendez@gmail.com}{adriana.menchacamendez@gmail.com}, \href{mailto:lamoradita@gmail.com}{lamoradita@gmail.com}. \href{mailto:mraggi@gmail.com}{mraggi@gmail.com}, \href{mailto:stinoco@enesmorelia.unam.mx}{stinoco@enesmorelia.unam.mx}, \href{mailto:catomi@gmail.com}{catomi@gmail.com}

\tcr{No puedo poner los emails!!!!!!! No sé cómo! Alguien arréglelo antes de que rompa la compu!}
\begin{abstract}
	We present a novel way of constructing an interaction network for ecological species using tools from fuzzy logic. We present a few (3???) examples: Quercus Oaxaca (?), Loba-whatever, and redes centro, which were obtained by doing bla and bla \tcr{César?}. We also release computational tools that take as input some observational data and output a network built using the methods described in this paper. Furthermore, the code to analyze said network is also freely released.
	\vspace{5pt}
Keywords: fuzzy logic, ecology, networks\\
 {\small Mathematics Subject Classification: ???} 
\end{abstract}

\section{Introduction}

In \cite{Hola} and \cite{cesarthesis} the authors do bla bla bla...

In this paper, we improve on that because of bla bla bla, and apply the results to bla bla and bla.

All the source code used for this paper can be freely downloaded and used (under the terms of the license) from
\begin{center}
	\url{https://www.github.com/mraggi/FuzzyLogicEcology}
\end{center}

Traditionally, the way to build an interaction network is to use circles or polygons or whatever, but that has the problems of... \tcr{César}

\subsection{A brief introduction to the tools of fuzzy logic}
In this section we introduce the reader to the fuzzy logic tools we used to build the interaction network. For a more complete treatment on the topic, see \cite{FuzzyLogicSuperBook} or \cite{FuzzyLogicSuperBook2}. 

We differentiate between regular sets (\emph{crisp} sets)  and \emph{fuzzy} sets. A fuzzy set is a set in which membership is not a boolean value, but rather is a number between 0 and 1, where a membership of 0 means that the element is not in the set and 1 means the element is definitely in the set. Values in between indicate how much an element belongs to a set.

Formally,
\begin{definition}
	A \textbf{fuzzy set} $A=(X,\mu_A)$ is a set $X$ together with a function $\mu_A:X \to [0,1]$. In this case we call $X$ the \emph{ground set} and $\mu_A$ the \emph{membership function} of $A$. Sometimes we refer to $\mu_A$ as the fuzzy set.
\end{definition}

We wish to define the standard set operations ($\subset,\setminus,\cap,\cup$) on fuzzy sets. 

\begin{definition}
	Let $A$ and $B$ be fuzzy sets on the same ground set $X$. Then,
	\begin{itemize}
		\item $A \subset B$ iff $\mu_A(x) \leq \mu_B(x)$ for every $x\in X$.
		\item $A\setminus B$ is defined by the characteristic function $\mu_{A\setminus B}(x) = \max(0,\mu_A(x)-\mu_B(x))$.
	\end{itemize}
\end{definition}

The above definitions are the only standard definition of $\subset$ and $\setminus$, but the definition of $\cap$ and therefore $\cup$ varies, as there are many ways to do so in a consistent and logical manner. Usually one gives the definition of $\cap$ as $\mu_{A\cap B} = \II(a,b)$, where  $\II : \RR^2 \to [0,1]$ is a function that satisfies the same properties as intersection when evaluated in $\{0,1\}$. The definition of $\cup$ follows. \tcr{paperize!}. 

\begin{definition}
A \emph{consistent} function $\II : [0,1]^2 \to [0,1]$ is one that
\begin{enumerate}
  \item $\II(a,b) = \II(b,a)$ for all $a,b$. (symmetry)
  \item $\II(0,b) = 0$ for all $b$.
  \item $\II(1,b) = b$ for all $a$.
  \item $\II(a,b) \leq \II(c,b)$ if $a \leq c$.
\end{enumerate}
\end{definition}

Once the intersection is defined as $\mu_{A\cap B}(p) := \II(\mu_A(p),\mu_B(p))$, the definition of $\cup$ easily follows as in the inclusion-exclusion principle: $\mu_{A\cup B} = \mu_A + \mu_B - \mu_{A\cup B}$.

It can be easily checked that if one defines intersection this way with a consistent $\II$, it satisfies many of the common properties of sets, such as commutativity for $\cap$ and $\cup$, associativity, De Morgan's laws, etc. when the corresponding crisp set properties are satisfied as well \tcr{paperizar!}.


%% new section? I don't know.

In this work we will consider two different definitions of $\II$. Both have advantages and disadvantages. 

The first definition we shall consider involves defining the operations akin to when considering independent sets in probability: $\II(a,b) = ab$.

\begin{definition}
	\begin{itemize}
		\item $A\cap B$ is defined by the membership function $\mu_{A\cap B} (x) := \mu_A(x)\mu_B(x)$
		\item $A\cup B$ is defined by the membership function $\mu_{A\cup B} (x) := \mu_A(x)+\mu_B(x)-\mu_A(x)\mu_B(x)$
	\end{itemize}
\end{definition}

The second definition, also quite common, is to define $\II(a,b) = \min(a,b)$. In this scenario, we observe that $\mu_{A\cup B}(p) = \max(\mu_A(p),\mu_B(p))$.

\section{Building the network}

The main idea behind the method is that instead of considering the distribution area of a species as a crisp set, we consider the distribution as a fuzzy set. The motivation behind this is that given an observation of an individual of a certain species, the area of effect of this individual in its interaction with other species will decay the further away one moves from this observation. \tcr{Este enunciado está terrible. Re-escribir! Y pasar para antes, probablemente.}

Let $\Omega \subset \RR^2$ denote the full area of distribution we are considering.

Let $P$ denote a point in $\Omega$ and $C > 0$ be real constant number. We define $f_P:\Omega \to [0,1]$ in the following way:
	$$f_P(Q) = e^{-C\left[d(P,Q)^2\right]}.$$
	where $d(P,Q)$ denotes the (Euclidean) distance from $P$ to $Q$.

	Now, for a certain species $\cA$, let $A \subset \Omega$ denote the set of observed locations of an individual of that species. It is common to find such data when doing field work of this type and ... \tcr{César? O quizás en la intro y aquí nada más decir ``As we previously mentioned, ...''}.

  \begin{definition}
	We define the \textbf{area of distribution} of species $\cA$ as the fuzzy set given by the following membership function:
		$$\mu_A = \cup_{a\in A} f_a$$
  \end{definition}
  
	\begin{figure}
	\begin{center}
		\includegraphics[scale=0.35]{./distribucion.png}
		\caption{Visualization of the area of distribution of a species}
	\end{center}
	
	\end{figure}
	
	Following the standard way of constructing interaction networks based on geographical data (\cite{cesarthesis}, \cite{cesarpaper1}), we build a weighted directed graph $D=(V,E)$ where $V$ is the set of species, and there is an edge $\cA \to \cB$ if their respective areas of distribution of $\cA$ and $\cB$ intersect, and the weight of this edge is defined as
	$$w(\cA \to \cB) = \frac{\area(\cA\cap\cB)}{\area(\cB)}$$

	Translating the above definition to the fuzzy world, we may calculate the weight as follows: if $\mu_A$ and $\mu_B$ are the respective membership functions of $\cA$ and $\cB$ as defined above, when $\II$ is the product function,
	$$w_P(\cA \to \cB) := \left(\int_\Omega \mu_A\mu_B\right)\big/\left(\int_\Omega \mu_A\right) $$
	and when $\II$ is the $\min$ function,
	$$w_M(\cA \to \cB) := \left(\int_\Omega \min(\mu_A,\mu_B)\right)\big/\left(\int_\Omega \mu_A\right) $$
	
\subsection{Calculating weights numerically}

We are left with the following computational problem: Given a set of species and for each species a set of points representing the observational data of the species in question, calculate the weighted digraph as above.

Obviously an analytical approach is a terrible way to do it \tcr{Bah, justifiquen esto uds. Daniele? Alguien?}

So we rely on numerical methods instead. First we'll describe how to find $\mu_A$ for each species $\cA$, and then we proceed to find $w(\cA\to\cB)$ for each pair of species $\cA$,$\cB$.

Divide $\Omega$ into an $n\times n$ grid. Then, each $\mu_A$ can be discretized and represented by an $n\times n$ matrix of real numbers. The higher $n$ is, the better the approximation. For all our experimental results, we found that $n \approx 5000$ is more than enough to get an accurate approximation. \tcr{Alguien se quisiera aventar el análisis de error? No? That's what I thought.}


\subsection{Normalizing}

	In a brute force approach, since for every point in the grid we have to consider every observation of said species, calculating the matrix associated with $\mu_A$ takes at least $\Theta(|A|n^2)$ time. To speed up computations by sacrificing \tcb{(a tiny amount of)} accuracy, note that 
		$$\mu_A \leq \sum_{a\in A} f_a.$$
		
	We note that the exponential decay in the formula for $f_a$ gives a quick way to only affect the area near point $a$. Therefore, if we admit an error of $\varepsilon > 0$ for each point in the grid, we only need to compute $f_a(p)$ for points $p$ near $a$ inside a circle of radius $R$, where
		$$R := f_a^{-1}(\varepsilon/|A|) = \sqrt{-\log\left(\frac{\varepsilon}{|A|C}\right)}$$
	
	In this way, calculating the matrix associated with $\mu_A$ takes $\Theta(|A|R^2 + n^2)$, a considerable speedup. This assumes, of course, that each point in the grid can be calculated in $\Theta(|A|)$ time, which is not immediate when $\II$ is the product. In the next section we make it so. \tcr{paperize}.
	
	With this in mind, we proceed to normalize as follows:
	\begin{center}
		\includegraphics[scale=0.5]{./continuoamalla.pdf}
	\end{center}
	
	First, let $O=(mx,my)$ and $W=(Mx,My)$, where $mx,my,Mx,My$ denote the minimum and maximum points in the dataset. Let $F=W-O$.

	Then, $b_x = R/|F_x|$ and $b_y = R/|F_y|$ are the $x$ and $y$ borders respectively. Any element of the grid outside the border would, by the definition of $R$, contain a number that is less than $\varepsilon$ and therefore can be ignored.
	
	Also, $C$ has to be transformed into $C_x$ and $C_y$ by the equation \tcr{look it up in the code}, because of \tcr{Daniele said so. I agreed he was correct, but I don't remember.}

\subsection{Finding \texorpdfstring{$\mu_A$}{mu\_A}}
Finding the matrix representing $\mu_A$ is straightforward when considering $\II$ as the min function. For the rest of this section, we consider only the case when $\II$ is the product function.

When $\II$ is the product function, however, things get a little more tricky \tcr{paperize}. By the inclusion-exclusion principle we have
	$$\mu_A = \sum_{a\in A} f_{a} - \sum_{a,b \in \binom{A}{2}} f_a f_b + \sum_{a,b,c \in \binom{A}{3} } f_a f_{b} f_{c} + \dots + (-1)^{N+1} \prod_{a\in A} f_a $$
We factorize $\mu_A$ as follows:
\begin{equation}\label{mu}\mu_A = 1-\prod_{a\in A} (1-f_a)\end{equation}

	

	\subsection{Finding \texorpdfstring{$w$}{w}}
	
	Once we have $\mu$ for every species, it's time to calculate $\int \mu_A\mu_B$ for every pair of species $\cA$, $\cB$. The straightforward approach has a complexity of $O(s^2n^2)$, where $s$ is the number of species and $n$ is the size of the grid. 
	
	We may speed up this computation when $\II$ is the product with the following trick. 
	
	Note that 
		$$\int \mu_A \mu_B \approx \sum_{0\leq x < n} \sum_{0\leq y < n} \mu_A[x,y]\mu_B[x,y]$$
	
	If we flatten the matrix $\mu_A$ and $\mu_B$ to vectors $\nu_A$ and $\nu_B$, this last sum is simply the dot product $\nu_A\cdot \nu_B$.
	
	So consider the $s\times n^2$ matrix 
	$$M = \begin{bmatrix}
	        \longleftarrow & \nu_0 & \longrightarrow \\
	        \longleftarrow & \nu_1 & \longrightarrow \\
	          & \dots &   \\
					\longleftarrow & \nu_{s-1} & \longrightarrow \\
	      \end{bmatrix}.
	$$
Then, $MM^T$ is an $s\times s$ matrix whose $(i,j)$-th entry contains $\int \mu_A \mu_B$. This can be done efficiently with fast matrix multiplication algorithms (\cite{strassen}) \tcr{(Marisol, tú te los sabes seguramente, pon unas palabritas de ellos y di que son super chidos y que no se que)}. Unfortunately, when $\II = \min$ this speedup is not possible, as fast matrix multiplication relies on the fact that $+$ and $\times$ are distributive.

Note also that the algorithms described here are highly parallelizable, since calculating the matrix associated with $\mu_A$ for one species does not rely on observations from any other species. Indeed, the provided software benefits considerably by using a computer with many cores. \tcr{paperize?}

\subsection{Advantages and disadvantages of min over product}

We gave two parallel ways to construct the distribution network: using products and using min. In this section we discuss the advantages and disadvantages of using each.

The clearest disadvantage of using the product is that $A\cap A \neq A$. So the weighted edge $w_P(\cA \to \cA) \neq 1$. This sucks. In general, in our experimental data, the edge weights become quite small. A way to alleviate this is to consider
	$$\widehat{w_P}(\cA \to \cB) := \left(\int_\Omega \mu_A\mu_B\right)\big/\left(\int_\Omega \mu_A^2\right)$$
	
This gives much better edge weights \tcr{paperize... justify?}, but has the disadvantage that an edge weight may be greater than 1. Using our experimental data. Since the edge weight $w(\cA \to \cB)$ is supposed to represent how what percentage of the area of distribution of $\cA$ is contained in the area of distribution of $\cB$, a value greater than 1 would mean that $\cA$ is more strongly contained in $\cB$ than in itself. This makes sense!! It's not bad!

\section{Experiments and results}

\subsection{Digraphs}
The following digraphs were obtained as a result of the algorithms described in the previous section. \tcr{(mm... damos las gráficas? La más chica es una matriz de $56\times56$, aunque podríamos dar sólo las aristas más pesadas... no sé)}

\subsection{Analysis of the digraphs}
This graphs are cool because here is the robustness and the analysis revealed deep and important truths \tcr{(Yo les doy los resultados del análisis. Uds. escriben por qué, para qué, cómo, cuándo, etc.)}



\section{Conclusions}

Finally, we conclude this awesome work. Please accept this paper!!


\section*{Acknowledgements}

This project was supported by PAPIIT IA106316.


\bibliographystyle{myamsalpha}
\bibliography{references}

\appendix
\section{On the mathematical expression of the area distribution}
We consider a species $A$ and denote by $N$ the number of its individuals; then the expression (\ref{mu}) reads:
\begin{equation}
\mu_A = \sum_{i=1}^N f_{i} - \sum_{i \neq j} f_{i} f_{j} + \sum_{i \neq j \neq k,  i \neq k } f_{i} f_{j} f_{k} + \cdots + (-1)^{N-1} \prod_{i=1}^Nf_i,
\end{equation}
or, in more compact notation,
\begin{equation}
\mu_A = \sum_{n=1}^N (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^N f_{i_1} \cdots f_{i_n}.
\end{equation}
Now we compute the integral of $\mu_A$ over all of space, i.e. over ${\mathbb R}^2$:
\begin{align}
&\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A(x,y) \nonumber\\
&=  \sum_{i=1}^N \int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) - \sum_{i \neq j} \int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) f_{j}(x,y)  \nonumber\\
& + \sum_{i \neq j \neq k,  i \neq k } \int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) f_{j}(x,y) f_{k}(x,y) + \cdots + (-1)^{N-1} \int_{{\mathbb R}^2} \xd x \, \xd y \,\prod_{i=1}^Nf_i(x,y), \nonumber\\
&= \sum_{n=1}^N (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^N
\int_{{\mathbb R}^2} \xd x \, \xd y \,  f_{i_1} (x,y)\cdots f_{i_n} (x,y).
\end{align}
Notice that if the $f_i$ are Gaussian distributions, then the first integral in the r.h.s. of the second line of the above expression results to be
\begin{equation}
\int_{{\mathbb R}^2} \xd x \, \xd y \, f_{i}(x,y) = \frac{\pi}{C}.
\end{equation}

We consider the integral of the product of $n$ Gaussians:
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \,  f_{i_1} (x,y)\cdots f_{i_n} (x,y) = \int_{{\mathbb R}^2} \xd x \, \xd y \,  \exp \left[ -C \sum_{\alpha=1}^n \left( (x-x_{i_{\alpha}})^2 + (y-y_{i_{\alpha}})^2 \right) \right].
\end{align}
Notice that 
\begin{equation}
\sum_{\alpha=1}^n  (x-x_{i_{\alpha}})^2 = n x^2 -2x \underbrace{\sum_{\alpha=1}^n x_{i_{\alpha}} }_{X_{1,n}}+ \underbrace{\sum_{\alpha=1}^n x_{i_{\alpha}}^2}_{X_{2,n}}.
\end{equation}
So, using the obvious notation,
\begin{align}
&\int_{{\mathbb R}^2} \xd x \, \xd y \,  f_{i_1} (x,y)\cdots f_{i_n} (x,y) \nonumber\\
&= \int_{{\mathbb R}^2} \xd x  \ \xd y \, \exp \left[ -Cn(x^2+y^2) +2C(X_{1,n} x +Y_{1,n}y) - C(X_{2,n}+Y_{2,n}) \right], \nonumber\\
&= \frac{\pi}{nC} \exp \left[ \frac{C(X_{1,n}^2+Y_{1,n}^2)}{n}  - C(X_{2,n}+Y_{2,n})\right], \nonumber\\
&= \frac{\pi}{nC} \exp \left[ \frac{C(\left( \sum_{\alpha=1}^n x_{i_{\alpha}}\right)^2+\left( \sum_{\alpha=1}^n y_{i_{\alpha}}\right)^2)}{n}  - C \sum_{\alpha=1}^n (x_{i_{\alpha}}^2+y_{i_{\alpha}}^2)\right], \nonumber\\
&=  \frac{\pi}{nC} \exp \left[ - \frac{C}{n} \sum_{1=\alpha<\beta}^n \left((x_{i_\alpha}-x_{i_\beta})^2 + (y_{i_{\alpha}}-y_{i_{\beta}})^2 \right) \right], \nonumber\\
&=  \frac{\pi}{nC} \exp \left[ - \frac{C}{n} \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 \right],
\end{align}
where $d_{i_{\alpha} i_{\beta}}$ is the (euclidean) distance between point $P_{i_{\alpha}} =(x_{i_{\alpha}} ,y_{i_{\alpha}} )$ and point $P_{i_{\beta}}=(x_{i_{\beta}},y_{i_{\beta}})$. Finally
\begin{equation}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A= \sum_{n=1}^N (-1)^{n+1} \sum_{ 1=i_1< \cdots <i_n }^N \frac{\pi}{nC} \exp \left[ - \frac{C}{n} \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 \right].
\end{equation}
Analogously we obtain the integral of the product of two membership functions
\begin{align}
\int_{{\mathbb R}^2} \xd x \, \xd y \, \mu_A \mu_B &=  \sum_{n=1}^{N_A} \sum_{\tilde{n}=1}^{N_B} (-1)^{n+\tilde{n}} \sum_{ 1=i_1< \cdots <i_n }^{N_A} \sum_{ 1=\tilde{i}_1< \cdots <\tilde{i}_n }^{N_B} \frac{\pi}{(n+\tilde{n})C}
 \nonumber\\
& \exp \left[ - \frac{C}{n+\tilde{n}} \left( \sum_{1=\alpha < \beta}^n d_{i_{\alpha} i_{\beta}}^2 + \sum_{1=\alpha < \beta}^{\tilde{n}} d_{\tilde{i}_{\alpha} \tilde{i}_{\beta}}^2 +
% \right. \right. \nonumber\\
%& \left. \left. 
\sum_{\alpha=1}^n \sum_{\tilde{\alpha}=1}^{\tilde{n}} 
d_{i_{\alpha} \tilde{i}_{\tilde{\alpha}}}^2
%\left[ (x_{i_{\alpha}} - x_{\tilde{i}_{\tilde{\alpha}}})^2 + (y_{i_{\alpha}} - y_{\tilde{i}_{\tilde{\alpha}}})^2\right]
\right) \right].
\end{align}

\end{document}